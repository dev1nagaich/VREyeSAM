# ğŸ‘ï¸ VREyeSAM  
### Virtual Reality Non-Frontal Iris Segmentation using Foundational Model with Uncertainty Weighted Loss

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)  
[![Paper](https://img.shields.io/badge/View-Paper-blue)](https://example.com) <!-- Add actual paper link here -->
[![Demo](Coming soon )

---

## ğŸ“Œ Overview

**VREyeSAM** introduces a novel approach for iris segmentation in virtual reality environments, focusing on challenging **non-frontal iris images** using **Segment Anything Model (SAM)** enhanced with **uncertainty-weighted loss**.  
This repository provides code, pretrained models, dataset instructions, and results to reproduce the findings from our paper:

> **Geetanjali Sharma<sup>1</sup>, Dev Nagachi<sup>1</sup>, Gaurav Jaswal<sup>2</sup>, Aditya Nigam<sup>1</sup>, Raghavendra Ramachandra<sup>3</sup>**  
> <sup>1</sup>Indian Institute of Technology Mandi, India  
> <sup>2</sup>Technology Innovation Hub, IIT Mandi, India  
> <sup>3</sup>Norwegian University of Science and Technology (NTNU), GjÃ¸vik, Norway

---

## ğŸŒŸ Key Contributions

- ğŸ“ A **fine-tuned Segment Anything Model** for non-frontal iris segmentation in VR setups.
- ğŸ“Š Integration of **uncertainty-weighted loss** for robust and reliable segmentation.
- ğŸ§  Evaluation on multiple challenging VR-based iris datasets.
- ğŸ† Achieved state-of-the-art results across various benchmarks.

---
